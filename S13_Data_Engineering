## Limpieza y preparación de datos con Janitor y Purr
## Exploración de datos y control de NAs con DataExplorer
## Imputation
## Imputation on TimeSeries
## Oversampling




library(janitor)

test_df <- as.data.frame(matrix(ncol = 6))
names(test_df) <- c("firstName", "ábc@!*", "% successful (2009)",
                    "REPEAT VALUE", "REPEAT VALUE", "") # nombres de columnas que darían problemas en R como tener espacios, columnas repetidas o *

# Limpiamos los nombres de los campos para que sean más fácil de interpretar
test_df %>%
  clean_names() 

# Con make.names creamos un vector con nombres corregidos
make.names(names(test_df))

############### tabyl better than table #################################################

#tabyl() is a tidyverse-oriented replacement for table(). 
#It counts combinations of one, two, or three variables, 
#and then can be formatted with a suite of adorn_* functions to look just how you want. 

# Motivation:
#table(), leaves much to be desired:
  
## It doesn't accept data.frame inputs (and thus doesn't play nicely with the %>% pipe)
## It doesn't output data.frames
## Its results are hard to format. Compare the look and formatting choices of an R table 
## to a Microsoft Excel PivotTable or even the table formatting provided by SPSS.

#tabyl() is an approach to tabulating variables that addresses these shortcomings. 
#It's part of the janitor package because counting is such a fundamental part of data 
#cleaning and exploration.

### example 1:

mtcars %>%
  tabyl(gear, cyl) %>%
  adorn_totals(where = "col") %>% # Para todas las filas calcula los totales
  adorn_percentages("row") %>% # Porcentajes para cada una de las filas
  adorn_pct_formatting(digits = 2) %>% # Formatea los porcentajes para mostrar únicamente 2 dígitos
  adorn_ns() %>% # Nos muestra el porcentaje además de ver el número de valores que había en cada columna
  adorn_title()

# Con table() no podemos acceder a los datos del resultado.
table(mtcars$cyl) 

#### example 2: starwars, dataset con todos los personajes y sus características

library(dplyr)
humans <- starwars %>%
  filter(species == "Human")

t1 <- humans %>%
  tabyl(eye_color) # Como sólo tenemos una variable, nos muestra automáticamente también el porcentaje

# it also works on vectors and does not count NAs
x <- c("big", "big", "small", "small", "small", NA)
tabyl(x)

t1 %>%
  adorn_totals("row") %>%
  adorn_pct_formatting()

# contingency table or crosstab 

t2 <- humans %>%
  tabyl(gender, eye_color)

t2 %>%
  adorn_percentages("row") %>%
  adorn_pct_formatting(digits = 2) %>%
  adorn_ns()

# 3 variables tabyl
t3 <- humans %>%
  tabyl(eye_color, skin_color, gender) 

#If the adorn_ helper functions are called on a list of data.frames 
#- like the output of a three-way tabyl call - they will call purrr::map() 
# to apply themselves to each data.frame in the list:
  
humans %>%
  tabyl(eye_color, skin_color, gender, show_missing_levels = FALSE) %>%
  adorn_totals("row") %>%
  adorn_percentages("all") %>%
  adorn_pct_formatting(digits = 1) %>%
  adorn_ns %>%
  adorn_title

#inciso: libreria purrr: map-> reduce

library(purrr)
mtcars %>%
  split(.$cyl) %>% # from base R, hace 4 tablas, uno por tipo de modelo dependiendo del número de cilindros
  map(~ lm(mpg ~ wt, data = .)) %>% # en map decimos la función que queremos que haga. Hacer una regresión entre las variables mpg y wt
  map(summary) %>%
  map_dbl("r.squared") # Nos muestra únicamente los valores de 'r.squared' de cada uno de lo summaries de cada número de cilindros

# more elegant tables printed using kable from knitr package

humans %>%
  tabyl(gender, eye_color) %>%
  adorn_totals(c("row", "col")) %>%
  adorn_percentages("row") %>% 
  adorn_pct_formatting(rounding = "half up", digits = 0) %>%
  adorn_ns() %>%
  adorn_title("combined") %>%
  knitr::kable() # Con kable() mostramos la tabla de manera más elegante

#You can also call adorn_ functions on other data.frames, 
#not only the results of calls to tabyl(). E.g., 

mtcars %>% adorn_totals("col") %>% adorn_percentages("col") %>% head()

#performs as expected, despite mtcars not being a tabyl.

# example 3:
percent_above_165_cm <- humans %>%
  group_by(gender) %>%
  summarise(pct_above_165_cm = mean(height > 165, na.rm = TRUE))

percent_above_165_cm %>%
  adorn_pct_formatting()

mpg_by_cyl_and_am <- mtcars %>%
  group_by(cyl, am) %>%
  summarise(mpg = mean(mpg)) %>%
  spread(am, mpg)

mpg_by_cyl_and_am


mpg_by_cyl_and_am %>%
  adorn_rounding() %>%
  adorn_ns(
    ns = mtcars %>% # calculate the Ns on the fly by calling tabyl on the original data
      tabyl(cyl, am)
  ) %>%
  adorn_title("combined", row_name = "Cylinders", col_name = "Is Automatic")


###################### other functions

#Explore records with duplicated values for specific combinations of variables with get_dupes()

get_dupes(mtcars, wt, cyl)

# remove_empty() rows and columns

q <- data.frame(v1 = c(1, NA, 3),
                v2 = c(NA, NA, NA),
                v3 = c("a", NA, "b"))
q %>%
  remove_empty(c("rows", "cols"))

#round_half_up()
nums <- c(2.5, 3.5)
round(nums)
round_half_up(nums)

# Count factor levels in groups of high, medium, and low with top_levels()

f <- factor(c("strongly agree", "agree", "neutral", "neutral", "disagree", "strongly agree"),
            levels = c("strongly agree", "agree", "neutral", "disagree", "strongly disagree"))
top_levels(f)

top_levels(f, n = 1)


------------------------------------------------------------------------------------------------------------------


#install.packages(c("nycflights13","DataExplorer"))
library(nycflights13)
library(DataExplorer)
data_list <- list(airlines, airports, flights, planes, weather)

##### Para visualizar la estructura de un dataset enorme de manera gráfica y sencilla:
plot_str(data_list)
# De manera radial
plot_str(data_list, type = "r")

# Unir tablas como si utilizáramos un JOIN
# Con all.x = True estamos haciendo una union (aparecerán NAs), y con all.x = False hacemos una intersección, por lo que sólo se unirán las filas que estén en ambas tablas
merge_airlines <- merge(flights, airlines, by = "carrier", all.x = TRUE) # une las 2 tablas por la columna "carrier" 
merge_planes <- merge(merge_airlines, planes, by = "tailnum", all.x = TRUE, suffixes = c("_flights", "_planes")) # En caso de columnas repetidas, indicamos que añada los sufijos indicados
merge_airports_origin <- merge(merge_planes, airports, by.x = "origin", by.y = "faa", all.x = TRUE, suffixes = c("_carrier", "_origin"))
final_data <- merge(merge_airports_origin, airports, by.x = "dest", by.y = "faa", all.x = TRUE, suffixes = c("_origin", "_dest"))

# Para conocer información sobre cada una de las columnas, el tipo que son, valores missings, etc...
introduce(final_data)
plot_intro(final_data)

# missing values:
plot_missing(final_data)
final_data <- drop_columns(final_data, "speed")

plot_bar(final_data)

# clean up duplications
# Manualmente cambiamos los que ponen Airbus Indistrie por únicamente Airbus
final_data[which(final_data$manufacturer == "AIRBUS INDUSTRIE"),]$manufacturer <- "AIRBUS" 
final_data[which(final_data$manufacturer == "CANADAIR LTD"),]$manufacturer <- "CANADAIR"
final_data[which(final_data$manufacturer %in% c("MCDONNELL DOUGLAS AIRCRAFT CO", "MCDONNELL DOUGLAS CORPORATION")),]$manufacturer <- "MCDONNELL DOUGLAS"

plot_bar(final_data$manufacturer)
table(final_data$manufacturer)

#Feature dst_origin and tzone_origin contains only 1 value, so we should drop them:
final_data <- drop_columns(final_data, c("dst_origin", "tzone_origin"))
plot_bar(final_data, with = "arr_delay")

#To visualize distributions for all continuous features:
plot_histogram(final_data)

#Set flight to categorical, since that is the flight number with no mathematical meaning:
final_data$flight <- as.factor(final_data$flight)

#Remove year_flights and tz_origin since there is only one value:
final_data <- drop_columns(final_data, c("year_flights", "tz_origin"))

# Para mostrar correlación entre variables de manera visual
plot_correlation(na.omit(final_data), maxcat = 5L)
# Para variables categóricas las convierte a valores numéricos, pero no es una aproximación muy adecuada.

# Nos eliimna los valores NA
pca_df <- na.omit(final_data[, c("origin", "dep_delay", "arr_delay", "air_time", "year_planes", "seats")]) # metemos todas las variables que hemos visto que tienen cierta correlación
  
plot_prcomp(pca_df, variance_cap = 1)  
  
## Reduce data size for demo purpose
arr_delay_df <- final_data[, c("arr_delay", "month", "day", "hour", "minute", "dep_delay", "distance", "year_planes", "seats")]
  
## Call boxplot function
plot_boxplot(arr_delay_df, by = "arr_delay")
  
## scatterplots
arr_delay_df2 <- final_data[, c("arr_delay", "dep_time", "dep_delay", "arr_time", "air_time", "distance", "year_planes", "seats")]
  
plot_scatterplot(arr_delay_df2, by = "arr_delay", sampled_rows = 1000L)  

  
############################################################################################
# Data Engineering: Missing values
############################################################################################
# Missing values may have meanings for a feature. 
# Other than imputation methods, we may also set them to some logical values. 
# For example, for discrete features, we may want to group missing values to a new category. 
# For continuous features, we may want to set missing values to a known number 
# based on existing knowledge.
# 
# In DataExplorer, this can be done by set_missing. 
# The function automatically matches the argument for either discrete or continuous features, 
# i.e., if you specify a number, all missing continuous values will be set to that number. 
# If you specify a string, all missing discrete values will be set to that string. 
# If you supply both, both types will be set.
  
final_df <- set_missing(final_data, list(0L, "unknown"))
plot_missing(final_df)  
  
############################################################################################
# Data Engineering: Group sparse categories
############################################################################################
group_category(data = final_data, feature = "manufacturer", threshold = 0.2)
#the bottom x% categories to be grouped, e.g., if set to 20%, 
#categories with cumulative frequency of the bottom 20% will be grouped

final_df <- group_category(data = final_data, feature = "manufacturer", 
                           threshold = 0.2, update = TRUE)
plot_bar(final_df$manufacturer)
  
group_category(data = final_data, feature = "name_carrier", 
               threshold = 0.2, measure = "distance")
final_df <- group_category(data = final_data, feature = "name_carrier", 
                           threshold = 0.2, measure = "distance", update = TRUE)
plot_bar(final_df$name_carrier)
  
  
############################################################################################
# Data Engineering: dummy encoding (one.hot)
############################################################################################
#Data dummification is also known as one hot encoding or feature binarization. 
#It turns each category to a distinct column with binary (numeric) values.

plot_str(
    list(
      "original" = final_data,
      "dummified" = dummify(final_data, maxcat = 5L)
    )
)
 
############################################################################################
# Data Engineering: drop features
############################################################################################
  identical(
    drop_columns(final_data, c("dst_dest", "tzone_dest")),
    drop_columns(final_data, c(36, 37))
  )
  
  ## [1] TRUE
  









------------------------------------------------------------------------------------------------------------------




install.packages("mice")
library(mice)

#########################################################################
#         example 1: CVD
#########################################################################

dat <- read.csv(url("https://goo.gl/4DYzru"), header=TRUE, sep=",")
head(dat)
sapply(dat, function(x) sum(is.na(x))) # Comprobamos que no hay ningún NA en el dataset
original <- dat

# Añadimos NAs de forma aleatoria
set.seed(10)
dat[sample(1:nrow(dat), 20), "Cholesterol"] <- NA
dat[sample(1:nrow(dat), 20), "Smoking"] <- NA
dat[sample(1:nrow(dat), 20), "Education"] <- NA
dat[sample(1:nrow(dat), 5), "Age"] <- NA
dat[sample(1:nrow(dat), 5), "BMI"] <- NA

#check where they are
sapply(dat, function(x) sum(is.na(x)))

#check variable type
library(dplyr) 
dat <- dat %>%
  mutate(
    Smoking = as.factor(Smoking),
    Education = as.factor(Education),
    Cholesterol = as.numeric(Cholesterol)
  )

str(dat)

######################### imputation ######################################
library(mice)
init = mice(dat, maxit=0) # el número de iteraciones
meth = init$method # Nos dice el método que ha utilizado para cada una de las variables, en Gender y SystolicBP no hemos metido NAs, por eso no hace nada
predM = init$predictorMatrix
predM[,"BMI"]=0
# Si no queremos que haga ningún ajuste para valores perdidos en una determinada columna
meth[c("Age")]=""

# we use different methods to predict each value since the variables are different
meth[c("Cholesterol")]="norm" 
meth[c("Smoking")]="logreg" 
meth[c("Education")]="polyreg"

# now run multiple imputation

set.seed(103)
imputed = mice(dat, method=meth, predictorMatrix=predM, m=5)
#create a data set
imputed <- mice::complete(imputed)

#Lets check how well we did it since we know the actual numbers
# Cholesterol
actual <- original$Cholesterol[is.na(dat$Cholesterol)]
predicted <- imputed$Cholesterol[is.na(dat$Cholesterol)]

# Smoking
actual <- original$Smoking[is.na(dat$Smoking)] 
predicted <- imputed$Smoking[is.na(dat$Smoking)] 
table(actual)
table(predicted)

#########################################################################
#         example 2: Air quality
#########################################################################
# Ahora los datos NA no están repartidos al azar
#remove some data
data <- airquality
data[4:10,3] <- rep(NA,7) # Para la variable 3 metemos 7 NAs de la variable 4 a la 10
data[1:5,4] <- NA

# check the distribution of the missings
data <- data[-c(5,6)]
summary(data)

# Para ver el porcentaje de valores perdidos para cada columna
plot_missing(data)

# Para detectar patrones de manera visual de número de NAs y columnas en que los hay
md.pattern(data)

# Para visualizar histograma y pattern a la vez
library(VIM)
aggr_plot <- aggr(data, col=c('navyblue','red'), 
                  numbers=TRUE, sortVars=TRUE, 
                  labels=names(data), cex.axis=.7, gap=3, 
                  ylab=c("Histogram of missing data","Pattern"))

#The plot helps us understanding that almost 70% of the samples are not missing any information,
#22% are missing the Ozone value, and the remaining ones show other missing patterns. 

marginplot(data[c(1,2)])

#The red box plot on the left shows the distribution of Solar.R with Ozone missing while the 
#blue box plot shows the distribution of the remaining datapoints. Likewhise for the Ozone 
#box plots at the bottom of the graph.
#If our assumption of MCAR data is correct, then we expect the red and blue box plots to be 
#very similar: i.e. the missing values in one and the other variable are independent from each other

# two types of missing data:
#MCAR: missing completely at random. This is the desirable scenario in case of missing data.

#MNAR: missing not at random. Missing not at random data is a more serious issue and in this 
#case it might be wise to check the data gathering process further and try to understand why 
#the information is missing. For instance, if most of the people in a survey did not answer 
#a certain question, why did they do that? Was the question unclear?

#Even for MCAR if more than 5% of the data is missing, leave the feature out
pMiss <- function(x){sum(is.na(x))/length(x)*100}
# % missing per variable
apply(data,2,pMiss)
#%missing per observation

apply(data,1,pMiss)

data<-mutate(data,missing.obs=apply(data,1,pMiss))

# Observations that are missing 2 or more features (>50%), should be dropped if possible.
data <- filter(data,missing.obs<50)
data<-select(data,-missing.obs)

##### Data imputation using mice
data <- airquality
data[4:10,3] <- rep(NA,7)
data[1:5,4] <- NA

# Maxit = número de iteraciones
# m = número de imputaciones múltiples (5 porque vamos a crear valores en 5 columnas)
tempData <- mice(data,m=5,maxit=50,meth='pmm',seed=500) 
summary(tempData)

tempData$imp$Ozone # Valores que se han añadido en la columna Ozone
tempData$meth
completedData <- mice::complete(tempData,1) 
#The missing values have been replaced with the imputed values in the first of the five datasets. 
#If you wish to use another one, just change the second parameter in the complete() function.

xyplot(tempData,Ozone ~ Wind+Temp+Solar.R,pch=18,cex=1)
densityplot(tempData)
stripplot(tempData, pch = 20, cex = 1.2)

########### pooling
# ideally we want to use not a single model but one pooling the results of the five estimations

modelFit1 <- with(tempData,lm(Temp~ Ozone+Solar.R+Wind))
summary(pool(modelFit1))

tempData2 <- mice(data,m=50,seed=245435)
modelFit2 <- with(tempData2,lm(Temp~ Ozone+Solar.R+Wind))
summary(pool(modelFit2))






------------------------------------------------------------------------------------------------------------------



library(imputeTS)

x <- ts(c(1, 2, 3, 4, 5, 6, 7, 8, NA, NA, 11, 12))

#impute using the mean of the whole series
na.mean(x)

# impute using the median
na.mean(x, option="median")

#since our data has an order might make sense to interpolate
na.interpolation(x)

# Cargamos dataset tsAirgap con número de pasajeros total que viajan cada mes desde 1949 a 1960.
tsAirgap
statsNA(tsAirgap) # El equivalente a un str() pero con datos sobre NAs y de su distribución en la serie temporal
plotNA.distribution(tsAirgap) # Visualización en un plot de la serie temporal y las zonas en rojo donde faltan datos.
plotNA.distributionBar(tsAirgap, breaks = 20)

# Aplicación del filtro Kalman para smoothing en series temporales
imp <- na.kalman(tsAirgap)
plotNA.imputations(tsAirgap, imp, tsAirgapComplete)

# Aplicación del filtro Kalman a la serie temporal del número de viajeros.
tsAirgap.imp <- na.mean(tsAirgap)
plotNA.imputations(tsAirgap, tsAirgap.imp)






------------------------------------------------------------------------------------------------------------------










------------------------------------------------------------------------------------------------------------------





